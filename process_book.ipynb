{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f9c743",
   "metadata": {},
   "source": [
    "## Process Book\n",
    "\n",
    "### 07.05.25\n",
    "\n",
    "Resources:\n",
    "- TheGuardian [URL](https://www.theguardian.com/books/2015/aug/17/the-100-best-novels-written-in-english-the-full-list)\n",
    "- [BeautifulSoup4](https://beautiful-soup-4.readthedocs.io/en/latest/)\n",
    "- [sqlite3](https://www.sqlite.org/)\n",
    "- [cs50 SQL library](https://cs50.readthedocs.io/libraries/cs50/python/)\n",
    "\n",
    "What I've worked on:\n",
    "- Navigating DOM of The Guardian to extract book titles and authors using REGEX\n",
    "- Data-cleaning (stripping white spaces and capitalizing)\n",
    "- Create SQL table for books, which can be gradually accumalated.\n",
    "\n",
    "Challenges:\n",
    "- Using REGEX to selectively extract only the authors name (and f.e. not the year of release)\n",
    "\n",
    "What I've learned:\n",
    "- More REGEX patterns (lookaheads, captures)\n",
    "- Updating SQL databases with UPDATE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f90f6e",
   "metadata": {},
   "source": [
    "### 08.05.25\n",
    "\n",
    "Resources\n",
    "- Goodreads.com [URL](https://www.goodreads.com/)\n",
    "- [BeautifulSoup4](https://beautiful-soup-4.readthedocs.io/en/latest/)\n",
    "- [sqlite3](https://www.sqlite.org/)\n",
    "- [cs50 SQL library](https://cs50.readthedocs.io/libraries/cs50/python/)\n",
    "\n",
    "What I've worked on:\n",
    "- Using book titles to extract the respective Goodreads descriptions\n",
    "- Adding description column to books table and adding descriptions for each book\n",
    "\n",
    "Challenges:\n",
    "- Scraping was required twice, once to find href to the book page from the search page, and once to find the description text on the book page.\n",
    "- Finding out how to add new column in a table and how to use UPDATE\n",
    "\n",
    "What I've learned:\n",
    "- By finding the href from the search page, I can navigate through multiple urls. \n",
    "- How to add new columns and how to update values for rows. \n",
    "\n",
    "Next Steps:\n",
    "- Process book descriptions into tokens\n",
    "- Remove stopwords\n",
    "- Standardize words conceptually (lemmatization)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cb18c4",
   "metadata": {},
   "source": [
    "### 09.05.25\n",
    "\n",
    "Resources\n",
    "- nltk.corpus.words\n",
    "- cs50s SQL library\n",
    "\n",
    "What I've worked on:\n",
    "- Detected and replaced inadequate summaries (less than 15 tokens, one summary was in greek)\n",
    "- Removed nonsense words, white spaces, and newlines from tokens.\n",
    "- Adjusted filtering for stopwords, non-alphabetical characters, and also using heuristics (not shorter than 2 characters)\n",
    "- Visualize variability in number of tokens per document\n",
    "\n",
    "Challenges:\n",
    "- I thought about if I should remove names, on the one hand they obviously would score high in the description of a book, on the other hand they are characteristic words. Decided to keep names in.\n",
    "- It was difficult to decide on what filters to use. There were some abbreviations (\"apr\", \"nov\", \"pa\") which I didn't like to have as keywords. I tried to use nltk.words to compare the tokens to a big set of english words, but this removed the names, and I wanted to include them. I decided on a heuristic, all tokens shorter than 3 characters are removed.\n",
    "\n",
    "What I've learned:\n",
    "- The existence of word sets from nltk.corpus, very useful, but ended up not using them as they would have excluded names\n",
    "- matplotlib.scatter has a gradient color argument, learnt about color maps\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8ed894",
   "metadata": {},
   "source": [
    "### 13.05.25\n",
    "\n",
    "Resources\n",
    "- Spacy library\n",
    "- sklearn.feature_extraction library\n",
    "- wordcloud library\n",
    "\n",
    "What I've worked on:\n",
    "- Writing general function using spacy Lemmatization and token attributes to tokenize and filter,and using sklearn's TfidfVectorizer() to create tf-idf matrix.\n",
    "- Create wordclouds for the top 15 words for each book using wordcloud library\n",
    "- Create search tool to find books with the top-n tf-idf scores for a particular word\n",
    "\n",
    "Challenges:\n",
    "- Familiarizing myself further with spacy, sklearn, and wordcloud library\n",
    "- Familiarize myself with TfidfVectorizer() and it's arguments, as well as which are useful for my application.\n",
    "- Honestly, most of the difficulty was dealing with the immensity of the data. It is difficult for so many documents and features to evaluate whether the tokenization and tf-idf computation was correct, or whether it was not good or could be improved. This took very long and required me to adjust my functions multiple times. \n",
    "\n",
    "What I've learned:\n",
    "- How to use Vectorizer objects\n",
    "- How to remove stopwords, numerics, and punctuation symbols using spacy. \n",
    "- How to create wordclouds.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224cee3",
   "metadata": {},
   "source": [
    "### 14.05.25\n",
    "\n",
    "Resources\n",
    "- Spacy library\n",
    "- sklearn.feature_extraction library\n",
    "- wordcloud library\n",
    "\n",
    "What I've worked on:\n",
    "- Still the same as last time \n",
    "\n",
    "Challenges:\n",
    "- Same as the day before\n",
    "\n",
    "What I've learned:\n",
    "- How to use Vectorizer objects\n",
    "- How to remove stopwords, numerics, and punctuation symbols using spacy. \n",
    "- How to create wordclouds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793a67f",
   "metadata": {},
   "source": [
    "### 15.05.25\n",
    "\n",
    "Resources\n",
    "- [Project Gutenberg](https://www.gutenberg.org/)\n",
    "- [BeautifulSoup4](https://beautiful-soup-4.readthedocs.io/en/latest/)\n",
    "\n",
    "\n",
    "What I've worked on:\n",
    "- Scraping full texts from Gutenberg.\n",
    "\n",
    "Challenges:\n",
    "- Project Gutenberg doesn't have all the books we used.\n",
    "- Using the default search query is tricky, as the first result on the page is not as reliable as with goodreads. Sometimes, a book has multiple pages, one with txt and one with audio (The Pilgrim's Progress by Bunyan). \n",
    "- Using the advanced search (with authors name and title) doesn't work, there is no url query we can use to tell the search page what to do. \n",
    "\n",
    "What I've learned:\n",
    "- Scraping from Project Gutenberg is really tricky, there is no way to do this reliably. Even if all my books were available, I'd have to identify the webpage with the txt version as opposed to audio or other formats. This is not visible from the search page. \n",
    "- Once again got reminded to use try-except, cause I spent a lot of time on figuring out where I went wrong in my code, and this (of course) would have saved me some time...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1506b5c6",
   "metadata": {},
   "source": [
    "### 17.05.25\n",
    "\n",
    "Resources\n",
    "- [Gutendex](https://gutendex.com/)\n",
    "- [Unicode](https://docs.python.org/3/library/unicodedata.html) library\n",
    "- [request.get](https://requests.readthedocs.io/en/latest/user/quickstart/)\n",
    "- \n",
    "\n",
    "What I've worked on:\n",
    "- Found an API for Project Gutenberg, called Gutendex. This API seems more reliable, because all formats are stored in one json entry (for one book). And using title and author names, I seem to get consistently the correct book.\n",
    "- Worked on the scraping function, which uses the json file from the query to identify the url to the text page. Then use request.get to download text and save it in sql table\n",
    "\n",
    "Challenges:\n",
    "- Took a lot of experimentation to understand the query system.\n",
    "- There were a lot of problems with characters/symbols of titles and authors, which got converted to unicode when entered as a query. I tried to replace these with the most common alphabetic equivalent (f.e. Emily Bronte instead of the actual spelling, Emily BrontÃ«). However, these would return no results, because the respective unicode for the replacement is different from the entry in the Gutendex database. Hence, I finally had to remove words with unique characters completely, assuming that queries missing one word would still get a result if it is on Gutenberg (f.e. \"Wuthering Heights Emily\" still gives me the correct search result).\n",
    "- Since the amount of data downloaded is very large and takes a lot of time, and due to me needing many attempts to get proper results, this step took the longest out of all. \n",
    "\n",
    "\n",
    "What I've learned:\n",
    "- Using Gutendex to get more reliable results in json format\n",
    "- Considering the Unicode version of certain characters when using requests and queries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c3f358",
   "metadata": {},
   "source": [
    "### 18.05.25\n",
    "\n",
    "Resources\n",
    "- Spacy\n",
    "- Pluckly\n",
    "\n",
    "\n",
    "What I've worked on:\n",
    "- Calculated TF-IDF matrix for the full texts, and extracted the keywords. \n",
    "- I noticed that there were certain nonsense words in my keywords. For the book \"The Sign of Four\" by Arthur Conan Doyle, the token \"holme\" had higher tf-idf score than \"holmes\". I realized that Spacy uses the capitalization of words in the base text to identify names vs nouns. I transformed all the text into lowercase before feeding it into the Spacy model. Doing this made spacy interpret \"holmes\" not as a name, and thus it tried to lemmatize it (holmes -> holme). I reverted the lowercase, and this problem was resolved.\n",
    "- Computing TF-IDF took also very long. In general, I have many computations that take quite a while. I found a library called pluckly, which allows me to save python data structures as binary files. This allowed me to load the data very quickly and not compute the tf-idf matrix again, unless I made some changes to tokenization.\n",
    "\n",
    "Challenges:\n",
    "- I tried to make my word clouds also have colour mapping, I wanted higher TF-IDF values to be reflected in a sequential change in colour. However, I didn't manage to implement that with the Wordcloud library...\n",
    "\n",
    "\n",
    "What I've learned:\n",
    "- Pluckly\n",
    "- Spacy predicts POS labels, very cool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca42ac2",
   "metadata": {},
   "source": [
    "### 22.05.25\n",
    "\n",
    "Resources\n",
    "- Spacy\n",
    "\n",
    "\n",
    "What I've worked on:\n",
    "- Comparing wordclouds between full texts and summaries, I noted that the majority of keywords are names for full texts. I therefore recalculated both tf-idf matrices without including names\n",
    "\n",
    "Challenges:\n",
    "- None\n",
    "\n",
    "\n",
    "What I've learned:\n",
    "- Accessing spacy's named entities predictions using the ents attribute of the fitted nlp() instances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb8e34",
   "metadata": {},
   "source": [
    "### 23.05.25\n",
    "\n",
    "Resources\n",
    "- [Cosine Similarity](https://www.datastax.com/guides/what-is-cosine-similarity)\n",
    "- Sklearn [cosine similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html)\n",
    "\n",
    "\n",
    "What I've worked on:\n",
    "- Plotted average tf-ifd values of keywords for each book, both for summaries and full text. Graphed out and compared full-text vs summary average tf-idfs\n",
    "- Created a book recommendation tool, which recommends books from the database, based on a selection books that you've read or like. Used cosine similarity for this.\n",
    "\n",
    "Challenges:\n",
    "- Thinking about how to create a comparison metric, was difficult, I couldn't find any resources on this. Also, it is difficult to evaluate the 'performance' of both models without a ground truth/gold standard. Comparing averages is based on the assumption that TF-IDF of smaller text sizes can be compared to those of bigger texts, I don't know if this is the case...\n",
    "\n",
    "What I've learned:\n",
    "- Using cosine similarity from sklearn. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
